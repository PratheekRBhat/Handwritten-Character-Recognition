{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Character Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "import warnings\n",
    "from imutils.contours import sort_contours\n",
    "import cv2 as cv\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "The two fucntions below are used to load the datasets to train the model. The datasets used here are MNIST dataset which has already been split into training and testing set and the NIST Special Database 19 which is a similar to MNIST but contains letters instead of numbers. Both the datasets are of CSV variants to maintain a common dimension between them to ease the integration process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_az_dataset(path):\n",
    "    dataset = pd.read_csv(path).astype('float32')\n",
    "    dataset.rename(columns={'0': 'label'}, inplace=True)\n",
    "\n",
    "    data = dataset.drop('label', axis=1)\n",
    "    labels = dataset['label']\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_digit_dataset(path1, path2):\n",
    "    dataset = pd.read_csv(path1).astype('float32')\n",
    "    dataset.rename(columns={'0': 'label'}, inplace=True)\n",
    "\n",
    "    data1 = dataset.drop('label', axis=1)\n",
    "    labels1 = dataset['label']\n",
    "\n",
    "    dataset = pd.read_csv(path2).astype('float32')\n",
    "    dataset.rename(columns={'0': 'label'}, inplace=True)\n",
    "\n",
    "    data2 = dataset.drop('label', axis=1)\n",
    "    labels2 = dataset['label']\n",
    "\n",
    "    data = data1.append(data2)\n",
    "    labels = labels1.append(labels2)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training model\n",
    "For this project, due to the presence of images and their classification, Convolutional Neural Networks have been used. The model contains four convulutions followed by two hidden layers and output layer. The activation for the convolutions and the hidden layers is 'relu' and for the ouput layer, it is 'softmax' as it helps with the multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(width, height, depth, classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # First two convolutions\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), input_shape=(width, height, depth), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2, 2),\n",
    "\n",
    "        # Next two convolutions\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2, 2),\n",
    "\n",
    "        # Flatten the results\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        # Two 256 neuron hidden layers\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "\n",
    "        # Output layer with 36 classes for all digits and letters\n",
    "        tf.keras.layers.Dense(classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading the dataset...\n",
      "dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import the datasets from load_dataset.py file\n",
    "print(\"[INFO] loading the dataset...\")\n",
    "(alpha_data, alpha_labels) = load_az_dataset('A_Z Handwritten Data.csv')\n",
    "(digit_data, digit_labels) = load_digit_dataset('mnist_train.csv', 'mnist_test.csv')\n",
    "print(\"dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the datasets\n",
    "Once the datasets are loaded, the two datasets are combined together so that they can be used to train the model. The labels of the NIST dataset are increased by a value of 10 to prevent overlapping with the MNIST datatset. It is then expanded and normalised. \n",
    "\n",
    "To combine the two datasets, 'vstack' and 'hstack' functions of the numpy library are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the labels of the alphabet dataset to prevent overlapping\n",
    "alpha_labels += 10\n",
    "\n",
    "# Combine the two datasets into one\n",
    "data = np.vstack([alpha_data, digit_data])\n",
    "labels = np.hstack([alpha_labels, digit_labels])\n",
    "\n",
    "# Expand the dimensions and normalize the data\n",
    "data = np.expand_dims(data, axis=-1)\n",
    "data = data / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into to training and testing sets\n",
    "The data is split using the 'train_test_split' function of the sklearn library. Once it is split, the train and test data are reshaped based on whether it is channel first or not. To check the channel, we're using keras.backend library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing data\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(\n",
    "    data,\n",
    "    labels,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Reshape the data into 3 dimensions. keras.backend is used to adjust teh data based on the channel ordering\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    train_data = train_data.reshape(train_data.shape[0], 1, 28, 28)\n",
    "    test_data = test_data.reshape(test_data.shape[0], 1, 28, 28)\n",
    "    input_shape = (1, 28, 28)\n",
    "else:\n",
    "    train_data = train_data.reshape(train_data.shape[0], 28, 28, 1)\n",
    "    test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)\n",
    "    input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation\n",
    "aug = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model.\n",
    "Now that the data is processed and ready, we can use it to train the model. The input shape for the model is (28, 28, 1) and the optimizer used here is 'Stochastic Gradient Descent'. This is mainly due to the size of the dataset and the computational speed of the optimizer. For the loss function, the 'Sparse Categorical Cross-Entropy' function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prath\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "[INFO] training the model...\n",
      "Epoch 1/50\n",
      "2592/2592 [==============================] - 358s 138ms/step - loss: 2.3232 - acc: 0.3761 - val_loss: 0.7191 - val_acc: 0.7907\n",
      "Epoch 2/50\n",
      "2592/2592 [==============================] - 338s 131ms/step - loss: 1.0495 - acc: 0.6989 - val_loss: 0.4393 - val_acc: 0.8701\n",
      "Epoch 3/50\n",
      "2592/2592 [==============================] - 337s 130ms/step - loss: 0.7859 - acc: 0.7714 - val_loss: 0.3538 - val_acc: 0.8954\n",
      "Epoch 4/50\n",
      "2592/2592 [==============================] - 338s 130ms/step - loss: 0.6793 - acc: 0.8016 - val_loss: 0.3088 - val_acc: 0.9080\n",
      "Epoch 5/50\n",
      "2592/2592 [==============================] - 339s 131ms/step - loss: 0.6215 - acc: 0.8179 - val_loss: 0.2870 - val_acc: 0.9138\n",
      "Epoch 6/50\n",
      "2592/2592 [==============================] - 339s 131ms/step - loss: 0.5782 - acc: 0.8300 - val_loss: 0.2781 - val_acc: 0.9167\n",
      "Epoch 7/50\n",
      "2592/2592 [==============================] - 339s 131ms/step - loss: 0.5483 - acc: 0.8382 - val_loss: 0.2639 - val_acc: 0.9200\n",
      "Epoch 8/50\n",
      "2592/2592 [==============================] - 343s 133ms/step - loss: 0.5303 - acc: 0.8433 - val_loss: 0.2583 - val_acc: 0.9212\n",
      "Epoch 9/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.5121 - acc: 0.8488 - val_loss: 0.2530 - val_acc: 0.9229\n",
      "Epoch 10/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.4953 - acc: 0.8533 - val_loss: 0.2528 - val_acc: 0.9219\n",
      "Epoch 11/50\n",
      "2592/2592 [==============================] - 341s 131ms/step - loss: 0.4857 - acc: 0.8562 - val_loss: 0.2459 - val_acc: 0.9254\n",
      "Epoch 12/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.4766 - acc: 0.8594 - val_loss: 0.2398 - val_acc: 0.9265\n",
      "Epoch 13/50\n",
      "2592/2592 [==============================] - 341s 132ms/step - loss: 0.4631 - acc: 0.8626 - val_loss: 0.2382 - val_acc: 0.9275\n",
      "Epoch 14/50\n",
      "2592/2592 [==============================] - 341s 132ms/step - loss: 0.4590 - acc: 0.8637 - val_loss: 0.2333 - val_acc: 0.9296\n",
      "Epoch 15/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.4495 - acc: 0.8661 - val_loss: 0.2292 - val_acc: 0.9295\n",
      "Epoch 16/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.4438 - acc: 0.8679 - val_loss: 0.2282 - val_acc: 0.9298\n",
      "Epoch 17/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.4376 - acc: 0.8698 - val_loss: 0.2274 - val_acc: 0.9304\n",
      "Epoch 18/50\n",
      "2592/2592 [==============================] - 341s 132ms/step - loss: 0.4340 - acc: 0.8705 - val_loss: 0.2265 - val_acc: 0.9299\n",
      "Epoch 19/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.4278 - acc: 0.8728 - val_loss: 0.2217 - val_acc: 0.9318\n",
      "Epoch 20/50\n",
      "2592/2592 [==============================] - 343s 132ms/step - loss: 0.4234 - acc: 0.8733 - val_loss: 0.2217 - val_acc: 0.9317\n",
      "Epoch 21/50\n",
      "2592/2592 [==============================] - 341s 132ms/step - loss: 0.4210 - acc: 0.8743 - val_loss: 0.2240 - val_acc: 0.9308\n",
      "Epoch 22/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.4163 - acc: 0.8758 - val_loss: 0.2199 - val_acc: 0.9317\n",
      "Epoch 23/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.4119 - acc: 0.8771 - val_loss: 0.2196 - val_acc: 0.9324\n",
      "Epoch 24/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.4119 - acc: 0.8772 - val_loss: 0.2134 - val_acc: 0.9342\n",
      "Epoch 25/50\n",
      "2592/2592 [==============================] - 343s 132ms/step - loss: 0.4041 - acc: 0.8786 - val_loss: 0.2152 - val_acc: 0.9340\n",
      "Epoch 26/50\n",
      "2592/2592 [==============================] - 341s 132ms/step - loss: 0.4060 - acc: 0.8784 - val_loss: 0.2143 - val_acc: 0.9337\n",
      "Epoch 27/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.4017 - acc: 0.8797 - val_loss: 0.2130 - val_acc: 0.9346\n",
      "Epoch 28/50\n",
      "2592/2592 [==============================] - 346s 134ms/step - loss: 0.3971 - acc: 0.8815 - val_loss: 0.2107 - val_acc: 0.9348\n",
      "Epoch 29/50\n",
      "2592/2592 [==============================] - 347s 134ms/step - loss: 0.3961 - acc: 0.8810 - val_loss: 0.2097 - val_acc: 0.9349\n",
      "Epoch 30/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.3963 - acc: 0.8819 - val_loss: 0.2111 - val_acc: 0.9348\n",
      "Epoch 31/50\n",
      "2592/2592 [==============================] - 343s 132ms/step - loss: 0.3935 - acc: 0.8823 - val_loss: 0.2098 - val_acc: 0.9350\n",
      "Epoch 32/50\n",
      "2592/2592 [==============================] - 342s 132ms/step - loss: 0.3911 - acc: 0.8827 - val_loss: 0.2085 - val_acc: 0.9355\n",
      "Epoch 33/50\n",
      "2592/2592 [==============================] - 343s 132ms/step - loss: 0.3878 - acc: 0.8842 - val_loss: 0.2092 - val_acc: 0.9353\n",
      "Epoch 34/50\n",
      "2592/2592 [==============================] - 339s 131ms/step - loss: 0.3866 - acc: 0.8840 - val_loss: 0.2067 - val_acc: 0.9362\n",
      "Epoch 35/50\n",
      "2592/2592 [==============================] - 339s 131ms/step - loss: 0.3854 - acc: 0.8845 - val_loss: 0.2079 - val_acc: 0.9360\n",
      "Epoch 36/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3838 - acc: 0.8853 - val_loss: 0.2079 - val_acc: 0.9356\n",
      "Epoch 37/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3824 - acc: 0.8857 - val_loss: 0.2056 - val_acc: 0.9367\n",
      "Epoch 38/50\n",
      "2592/2592 [==============================] - 339s 131ms/step - loss: 0.3812 - acc: 0.8854 - val_loss: 0.2057 - val_acc: 0.9361\n",
      "Epoch 39/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3798 - acc: 0.8863 - val_loss: 0.2037 - val_acc: 0.9370\n",
      "Epoch 40/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3770 - acc: 0.8869 - val_loss: 0.2058 - val_acc: 0.9362\n",
      "Epoch 41/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3768 - acc: 0.8869 - val_loss: 0.2059 - val_acc: 0.9367\n",
      "Epoch 42/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3724 - acc: 0.8886 - val_loss: 0.2009 - val_acc: 0.9381\n",
      "Epoch 43/50\n",
      "2592/2592 [==============================] - 341s 131ms/step - loss: 0.3727 - acc: 0.8881 - val_loss: 0.2038 - val_acc: 0.9377\n",
      "Epoch 44/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3712 - acc: 0.8884 - val_loss: 0.2002 - val_acc: 0.9382\n",
      "Epoch 45/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3697 - acc: 0.8890 - val_loss: 0.2026 - val_acc: 0.9377\n",
      "Epoch 46/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3698 - acc: 0.8891 - val_loss: 0.2017 - val_acc: 0.9380\n",
      "Epoch 47/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3683 - acc: 0.8898 - val_loss: 0.1992 - val_acc: 0.9387\n",
      "Epoch 48/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3683 - acc: 0.8902 - val_loss: 0.1986 - val_acc: 0.9389\n",
      "Epoch 49/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3646 - acc: 0.8905 - val_loss: 0.1989 - val_acc: 0.9389\n",
      "Epoch 50/50\n",
      "2592/2592 [==============================] - 340s 131ms/step - loss: 0.3643 - acc: 0.8904 - val_loss: 0.1987 - val_acc: 0.9386\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "# Import the model and build it\n",
    "model = build(28, 28, 1, 36)\n",
    "\n",
    "# Compile the model\n",
    "opt = tf.keras.optimizers.SGD(lr=0.01, decay=0.01 / 50)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# To filter out unnecessary warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fitting the model\n",
    "print(\"[INFO] training the model...\")\n",
    "history = model.fit(\n",
    "    aug.flow(train_data, train_labels, batch_size=128),\n",
    "    validation_data=(test_data, test_labels),\n",
    "    steps_per_epoch=len(train_data) // 128,\n",
    "    epochs=50,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# saving the model\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"ocr\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the accuracy and loss of the model\n",
    "Matplotlib is used here to plot the training and validation accuracy as well the respective losses of the model. This will give more insight into the performance over time of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# construct a plot that plots and saves the training history\n",
    "N = np.arange(0, 50)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the image\n",
    "In this section, code relevant to reading the image file and isolating the text for classification is done. This is done by detecting the contours of the text and looping over each contour, extracting the character, feeding to the model and labelling it. The label is then returned to the image and stored there.\n",
    "\n",
    "To perform all these operations, the 'opencv' library is extensively used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the input image from disk, converting it to grayscale, and blurring it to reduce noise\n",
    "image = cv.imread('ocr4.jpg')\n",
    "gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "blurred = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "# performing edge detection, finding contours in the edge map, and sorting the resulting contours from left-to-right\n",
    "edged = cv.Canny(blurred, 30, 150)\n",
    "cnts = cv.findContours(edged.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
    "\n",
    "# initializing the list of contour bounding boxes and associated characters that we'll be OCR'ing\n",
    "chars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the contours\n",
    "for c in cnts:\n",
    "    # compute the bounding box of the contour\n",
    "    (x, y, w, h) = cv.boundingRect(c)\n",
    "    # filter out bounding boxes, ensuring they are neither too small\n",
    "    # nor too large\n",
    "    if (w >= 5 and w <= 150) and (h >= 15 and h <= 120):\n",
    "        # extract the character and threshold it to make the character\n",
    "        # appear as *white* (foreground) on a *black* background, then\n",
    "        # grab the width and height of the thresholded image\n",
    "        roi = gray[y:y + h, x:x + w]\n",
    "        thresh = cv.threshold(roi, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)[1]\n",
    "        (tH, tW) = thresh.shape\n",
    "        # if the width is greater than the height, resize along the width dimension\n",
    "        if tW > tH:\n",
    "            thresh = imutils.resize(thresh, width=28)\n",
    "        # otherwise, resize along the height\n",
    "        else:\n",
    "            thresh = imutils.resize(thresh, height=28)\n",
    "            \n",
    "        # re-grab the image dimensions (now that its been resized)\n",
    "        # and then determine how much we need to pad the width and\n",
    "        # height such that our image will be 28x28\n",
    "        (tH, tW) = thresh.shape\n",
    "        dX = int(max(0, 28 - tW) / 2.0)\n",
    "        dY = int(max(0, 28 - tH) / 2.0)\n",
    "        # pad the image and force 28x28 dimensions\n",
    "        padded = cv.copyMakeBorder(thresh, top=dY, bottom=dY, left=dX, right=dX, borderType=cv.BORDER_CONSTANT, \n",
    "                                    value=(0, 0, 0))\n",
    "        padded = cv.resize(padded, (28, 28))\n",
    "        # prepare the padded image for classification via our handwriting OCR model\n",
    "        padded = padded.astype(\"float32\") / 255.0\n",
    "        padded = np.expand_dims(padded, axis=-1)\n",
    "        # update our list of characters that will be OCR'd\n",
    "        chars.append((padded, (x, y, w, h)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the bounding box locations and padded characters\n",
    "boxes = [b[1] for b in chars]\n",
    "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
    "\n",
    "# OCR the characters using our handwriting recognition model\n",
    "model = tf.keras.models.load_model('ocr')\n",
    "preds = model.predict(chars)\n",
    "\n",
    "# define the list of label names\n",
    "labelNames = '0123456789'\n",
    "labelNames += 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "labelNames = [l for l in labelNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] A - 40.22%\n",
      "[INFO] C - 91.31%\n",
      "[INFO] 9 - 86.77%\n",
      "[INFO] 3 - 99.89%\n",
      "[INFO] 6 - 52.76%\n",
      "[INFO] K - 93.49%\n",
      "[INFO] S - 97.90%\n"
     ]
    }
   ],
   "source": [
    "# loop over the predictions and bounding box locations together\n",
    "for (pred, (x, y, w, h)) in zip(preds, boxes):\n",
    "    # find the index of the label with the largest corresponding probability, then extract the probability and label\n",
    "    i = np.argmax(pred)\n",
    "    prob = pred[i]\n",
    "    label = labelNames[i]\n",
    "    \n",
    "    # draw the prediction on the image\n",
    "    print(\"[INFO] {} - {:.2f}%\".format(label, prob * 100))\n",
    "    cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv.putText(image, label, (x - 10, y - 10), cv.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "    \n",
    "    # show the image\n",
    "    cv.imshow(\"Image\", image)\n",
    "    cv.waitKey(5000)\n",
    "    \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
