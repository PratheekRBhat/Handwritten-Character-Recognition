{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hcr_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5htEIAQES7dML+iX0abm+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhuN-9iOCTM2"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import cv2 as cv\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx8zJ6MZlf6f"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/A_Z Handwritten Data.csv\").astype('float32')\r\n",
        "dataset.rename(columns={'0':'label'}, inplace=True)\r\n",
        "\r\n",
        "# Split into data and labels \r\n",
        "alpha_data = dataset.drop('label',axis = 1)\r\n",
        "alpha_labels = dataset['label']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCRqTahlmZAr"
      },
      "source": [
        "# The below step is to make sure both mnist and the alphabet dataset are of the same dimension.\r\n",
        "# The standard mnist dataset has 3 dimensions while alphabet has 2. So a separate dataset was used from\r\n",
        "# Kaggle where the dataset was split into train and test. They have been combined in the below code.\r\n",
        "\r\n",
        "dataset = pd.read_csv(\"/content/mnist_train.csv\").astype('float32')\r\n",
        "dataset.rename(columns={'0':'label'}, inplace=True)\r\n",
        "\r\n",
        "digit_data1 = dataset.drop('label',axis = 1)\r\n",
        "digits_labels1 = dataset['label']\r\n",
        "\r\n",
        "dataset = pd.read_csv(\"/content/mnist_test.csv\").astype('float32')\r\n",
        "dataset.rename(columns={'0':'label'}, inplace=True)\r\n",
        "\r\n",
        "digit_data2 = dataset.drop('label',axis = 1)\r\n",
        "digits_labels2 = dataset['label']\r\n",
        "\r\n",
        "# append both the datasets together\r\n",
        "digit_data = digit_data1.append(digit_data2)\r\n",
        "digits_labels = digits_labels1.append(digits_labels2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TASo4uho1pe"
      },
      "source": [
        "# Change the labels to avoid overlapping with the digit dataset\r\n",
        "alpha_labels += 10\r\n",
        "\r\n",
        "#combine both the datasets into a single dataset\r\n",
        "data = np.vstack([alpha_data, digit_data])\r\n",
        "labels = np.hstack([alpha_labels, digits_labels])\r\n",
        "\r\n",
        "#expand the dimensions and normalise the data\r\n",
        "data = np.expand_dims(data, axis=-1)\r\n",
        "data = data / 255.0\r\n",
        "\r\n",
        "# Splitting the dataset below\r\n",
        "(x_train, x_test, y_train, y_test) =  train_test_split(data, labels, test_size=0.25, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfgnIzW73HAv"
      },
      "source": [
        "# Reshape the data into 3 dimensions. keras.backend is used to adjust teh data based on the channel ordering\r\n",
        "\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "\r\n",
        "if K.image_data_format() == 'channels_first':\r\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, 28,28)\r\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\r\n",
        "  input_shape = (1, 28, 28)\r\n",
        "else:\r\n",
        "  x_train = x_train.reshape(x_train.shape[0],28, 28, 1)\r\n",
        "  x_test = x_test.reshape(x_test.shape[0],28, 28, 1)\r\n",
        "  input_shape = (28, 28, 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g2Zwn4yqRwD"
      },
      "source": [
        "# Image augmentation\r\n",
        "aug = tf.keras.preprocessing.image.ImageDataGenerator(\r\n",
        "    rotation_range=30,\r\n",
        "    width_shift_range=0.2,\r\n",
        "    height_shift_range=0.2,\r\n",
        "    zoom_range=0.2,\r\n",
        "    shear_range=0.2,\r\n",
        "    fill_mode='nearest'\r\n",
        ") "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX9qQET9zZZT"
      },
      "source": [
        "# A typical deep learning model with two middle layers.\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "    # First two convolutions\r\n",
        "    tf.keras.layers.Conv2D(32, (3,3), input_shape=(28, 28, 1), activation='relu'),\r\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPool2D(2, 2),\r\n",
        "    tf.keras.layers.Dropout(0.25),\r\n",
        "    # Next two convolutions\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPool2D(2, 2),\r\n",
        "    tf.keras.layers.Dropout(0.25),\r\n",
        "    # Flatten the results\r\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\r\n",
        "    # Two 256 neuron hidden layers\r\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\r\n",
        "    # Output layer with 36 classes for all digits and letters\r\n",
        "    tf.keras.layers.Dense(36, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "opt = tf.keras.optimizers.SGD(lr=0.001)\r\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX3ElVLpGIbH"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7xR6t270GVl",
        "outputId": "03a207eb-0c08-476b-aa1c-1df4e39ab7ed"
      },
      "source": [
        "model.fit(\r\n",
        "    x_train,\r\n",
        "    y_train,\r\n",
        "    epochs=20\r\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10370/10370 [==============================] - 756s 73ms/step - loss: 2.8293 - accuracy: 0.2667\n",
            "Epoch 2/20\n",
            "10370/10370 [==============================] - 751s 72ms/step - loss: 0.5945 - accuracy: 0.8264\n",
            "Epoch 3/20\n",
            "10370/10370 [==============================] - 753s 73ms/step - loss: 0.3922 - accuracy: 0.8848\n",
            "Epoch 4/20\n",
            "10370/10370 [==============================] - 751s 72ms/step - loss: 0.3192 - accuracy: 0.9065\n",
            "Epoch 5/20\n",
            "10370/10370 [==============================] - 750s 72ms/step - loss: 0.2762 - accuracy: 0.9184\n",
            "Epoch 6/20\n",
            "10370/10370 [==============================] - 746s 72ms/step - loss: 0.2480 - accuracy: 0.9273\n",
            "Epoch 7/20\n",
            "10370/10370 [==============================] - 748s 72ms/step - loss: 0.2260 - accuracy: 0.9331\n",
            "Epoch 8/20\n",
            "10370/10370 [==============================] - 748s 72ms/step - loss: 0.2102 - accuracy: 0.9380\n",
            "Epoch 9/20\n",
            "10370/10370 [==============================] - 748s 72ms/step - loss: 0.2015 - accuracy: 0.9413\n",
            "Epoch 10/20\n",
            "10370/10370 [==============================] - 751s 72ms/step - loss: 0.1885 - accuracy: 0.9443\n",
            "Epoch 11/20\n",
            "10370/10370 [==============================] - 748s 72ms/step - loss: 0.1803 - accuracy: 0.9469\n",
            "Epoch 12/20\n",
            "10370/10370 [==============================] - 747s 72ms/step - loss: 0.1728 - accuracy: 0.9494\n",
            "Epoch 13/20\n",
            "10370/10370 [==============================] - 749s 72ms/step - loss: 0.1658 - accuracy: 0.9508\n",
            "Epoch 14/20\n",
            "10370/10370 [==============================] - 748s 72ms/step - loss: 0.1577 - accuracy: 0.9535\n",
            "Epoch 15/20\n",
            "10370/10370 [==============================] - 749s 72ms/step - loss: 0.1543 - accuracy: 0.9546\n",
            "Epoch 16/20\n",
            "10370/10370 [==============================] - 753s 73ms/step - loss: 0.1499 - accuracy: 0.9554\n",
            "Epoch 17/20\n",
            "10370/10370 [==============================] - 748s 72ms/step - loss: 0.1435 - accuracy: 0.9573\n",
            "Epoch 18/20\n",
            "10370/10370 [==============================] - 749s 72ms/step - loss: 0.1422 - accuracy: 0.9576\n",
            "Epoch 19/20\n",
            "10370/10370 [==============================] - 747s 72ms/step - loss: 0.1372 - accuracy: 0.9594\n",
            "Epoch 20/20\n",
            "10370/10370 [==============================] - 748s 72ms/step - loss: 0.1349 - accuracy: 0.9595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff322d474a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nnTGvtV0LoN",
        "outputId": "4740e812-925c-40e2-90a3-d8dca0318b10"
      },
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\r\n",
        "print(accuracy*100)\r\n",
        "print(loss)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3457/3457 [==============================] - 64s 18ms/step - loss: 0.0990 - accuracy: 0.9715\n",
            "97.14771509170532\n",
            "0.09901438653469086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8xKIQJg4edM",
        "outputId": "2c86aa5c-4c2c-4ac1-c2cd-e7d48d2f1b92"
      },
      "source": [
        "from keras.preprocessing.image import load_img\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        " \r\n",
        "# load and prepare the image\r\n",
        "def load_image(filename):\r\n",
        "\t# load the image\r\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\r\n",
        "\t# convert to array\r\n",
        "\timg = img_to_array(img)\r\n",
        "\t# reshape into a single sample with 1 channel\r\n",
        "\timg = img.reshape(1, 28, 28, 1)\r\n",
        "\t# prepare pixel data\r\n",
        "\timg = img.astype('float32')\r\n",
        "\timg = img / 255.0\r\n",
        "\treturn img\r\n",
        " \r\n",
        "# load an image and predict the class\r\n",
        "def run_example():\r\n",
        "\t# load the image\r\n",
        "\timg = load_image('7.png')\r\n",
        "\t# predict the class\r\n",
        "\tdigit = model.predict_classes(img)\r\n",
        "\tprint(digit[0])\r\n",
        " \r\n",
        "# entry point, run the example\r\n",
        "run_example()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F52xGsh--5ar"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}