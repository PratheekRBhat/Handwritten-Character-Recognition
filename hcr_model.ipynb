{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hcr_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJ8nVf+1wpwpiEbidTclgP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhuN-9iOCTM2"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import cv2 as cv\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx8zJ6MZlf6f"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/A_Z Handwritten Data.csv\").astype('float32')\r\n",
        "dataset.rename(columns={'0':'label'}, inplace=True)\r\n",
        "\r\n",
        "# Split into data and labels \r\n",
        "alpha_data = dataset.drop('label',axis = 1)\r\n",
        "alpha_labels = dataset['label']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCRqTahlmZAr"
      },
      "source": [
        "# The below step is to make sure both mnist and the alphabet dataset are of the same dimension.\r\n",
        "# The standard mnist dataset has 3 dimensions while alphabet has 2. So a separate dataset was used from\r\n",
        "# Kaggle where the dataset was split into train and test. They have been combined in the below code.\r\n",
        "\r\n",
        "dataset = pd.read_csv(\"/content/mnist_train.csv\").astype('float32')\r\n",
        "dataset.rename(columns={'0':'label'}, inplace=True)\r\n",
        "\r\n",
        "digit_data1 = dataset.drop('label',axis = 1)\r\n",
        "digits_labels1 = dataset['label']\r\n",
        "\r\n",
        "dataset = pd.read_csv(\"/content/mnist_test.csv\").astype('float32')\r\n",
        "dataset.rename(columns={'0':'label'}, inplace=True)\r\n",
        "\r\n",
        "digit_data2 = dataset.drop('label',axis = 1)\r\n",
        "digits_labels2 = dataset['label']\r\n",
        "\r\n",
        "# append both the datasets together\r\n",
        "digit_data = digit_data1.append(digit_data2)\r\n",
        "digits_labels = digits_labels1.append(digits_labels2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TASo4uho1pe"
      },
      "source": [
        "# Change the labels to avoid overlapping with the digit dataset\r\n",
        "alpha_labels += 10\r\n",
        "\r\n",
        "#combine both the datasets into a single dataset\r\n",
        "data = np.vstack([alpha_data, digit_data])\r\n",
        "labels = np.hstack([alpha_labels, digits_labels])\r\n",
        "\r\n",
        "#expand the dimensions and normalise the data\r\n",
        "data = np.expand_dims(data, axis=-1)\r\n",
        "data = data / 255.0\r\n",
        "\r\n",
        "# Splitting the dataset below\r\n",
        "(x_train, x_test, y_train, y_test) =  train_test_split(data, labels, test_size=0.25, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfgnIzW73HAv"
      },
      "source": [
        "# Reshape the data into 3 dimensions. keras.backend is used to adjust teh data based on the channel ordering\r\n",
        "\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "\r\n",
        "if K.image_data_format() == 'channels_first':\r\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, 28,28)\r\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\r\n",
        "  input_shape = (1, 28, 28)\r\n",
        "else:\r\n",
        "  x_train = x_train.reshape(x_train.shape[0],28, 28, 1)\r\n",
        "  x_test = x_test.reshape(x_test.shape[0],28, 28, 1)\r\n",
        "  input_shape = (28, 28, 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g2Zwn4yqRwD"
      },
      "source": [
        "# Image augmentation\r\n",
        "aug = tf.keras.preprocessing.image.ImageDataGenerator(\r\n",
        "    rotation_range=30,\r\n",
        "    width_shift_range=0.2,\r\n",
        "    height_shift_range=0.2,\r\n",
        "    zoom_range=0.2,\r\n",
        "    shear_range=0.2,\r\n",
        "    fill_mode='nearest'\r\n",
        ") "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX9qQET9zZZT"
      },
      "source": [
        "# A typical deep learning model with two middle layers.\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\r\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(36, activation='softmax')\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX3ElVLpGIbH"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7xR6t270GVl",
        "outputId": "81e61d34-25e3-4781-ec6e-fde939695979"
      },
      "source": [
        "model.fit(\r\n",
        "    x_train,\r\n",
        "    y_train,\r\n",
        "    epochs=10\r\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10370/10370 [==============================] - 24s 2ms/step - loss: 0.5246 - accuracy: 0.8566\n",
            "Epoch 2/10\n",
            "10370/10370 [==============================] - 22s 2ms/step - loss: 0.1614 - accuracy: 0.9530\n",
            "Epoch 3/10\n",
            "10370/10370 [==============================] - 22s 2ms/step - loss: 0.1275 - accuracy: 0.9623\n",
            "Epoch 4/10\n",
            "10370/10370 [==============================] - 22s 2ms/step - loss: 0.1070 - accuracy: 0.9684\n",
            "Epoch 5/10\n",
            "10370/10370 [==============================] - 22s 2ms/step - loss: 0.0941 - accuracy: 0.9719\n",
            "Epoch 6/10\n",
            "10370/10370 [==============================] - 23s 2ms/step - loss: 0.0873 - accuracy: 0.9737\n",
            "Epoch 7/10\n",
            "10370/10370 [==============================] - 23s 2ms/step - loss: 0.0800 - accuracy: 0.9757\n",
            "Epoch 8/10\n",
            "10370/10370 [==============================] - 23s 2ms/step - loss: 0.0760 - accuracy: 0.9770\n",
            "Epoch 9/10\n",
            "10370/10370 [==============================] - 25s 2ms/step - loss: 0.0710 - accuracy: 0.9785\n",
            "Epoch 10/10\n",
            "10370/10370 [==============================] - 24s 2ms/step - loss: 0.0674 - accuracy: 0.9796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff3259d28d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nnTGvtV0LoN",
        "outputId": "a7ae526a-82e0-4115-bd75-2ecef9e561d2"
      },
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\r\n",
        "print(accuracy*100)\r\n",
        "print(loss)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3457/3457 [==============================] - 4s 1ms/step - loss: 0.1303 - accuracy: 0.9702\n",
            "97.01752662658691\n",
            "0.13025005161762238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8xKIQJg4edM",
        "outputId": "2c86aa5c-4c2c-4ac1-c2cd-e7d48d2f1b92"
      },
      "source": [
        "from keras.preprocessing.image import load_img\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        " \r\n",
        "# load and prepare the image\r\n",
        "def load_image(filename):\r\n",
        "\t# load the image\r\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\r\n",
        "\t# convert to array\r\n",
        "\timg = img_to_array(img)\r\n",
        "\t# reshape into a single sample with 1 channel\r\n",
        "\timg = img.reshape(1, 28, 28, 1)\r\n",
        "\t# prepare pixel data\r\n",
        "\timg = img.astype('float32')\r\n",
        "\timg = img / 255.0\r\n",
        "\treturn img\r\n",
        " \r\n",
        "# load an image and predict the class\r\n",
        "def run_example():\r\n",
        "\t# load the image\r\n",
        "\timg = load_image('7.png')\r\n",
        "\t# predict the class\r\n",
        "\tdigit = model.predict_classes(img)\r\n",
        "\tprint(digit[0])\r\n",
        " \r\n",
        "# entry point, run the example\r\n",
        "run_example()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F52xGsh--5ar"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}